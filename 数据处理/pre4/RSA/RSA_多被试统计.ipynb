{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "from pandas import read_csv\n",
    "import mne\n",
    "from mne.io import read_raw_fif\n",
    "from mne.datasets import visual_92_categories\n",
    "from neurora.nps_cal import nps\n",
    "from neurora.rdm_cal import eegRDM\n",
    "from neurora.rdm_corr import rdm_correlation_spearman\n",
    "from neurora.corr_cal_by_rdm import rdms_corr\n",
    "from neurora.rsa_plot import plot_rdm, plot_corrs_by_time, plot_nps_hotmap, plot_corrs_hotmap\n",
    "import pandas as pd\n",
    "\n",
    "from neurora.rsa_plot import plot_tbytsim_withstats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:27:23.339345100Z",
     "start_time": "2023-05-27T16:27:23.214220100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4010_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1159 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4012_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1141 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4013_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1270 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4015_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1104 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4017_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1325 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4018_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1064 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4019_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1123 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4021_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1222 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4022_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "996 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4023_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1310 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4026_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1284 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4027_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1261 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading E:\\实验\\阅读困难\\数据处理\\pre4\\data\\6epoch_clean_RSA\\pre4030_y_RSA-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1255 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n思路，先求ERP，然后再给ndarray，然后再计算RDM\\n'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_epochs_all = list()\n",
    "\n",
    "\n",
    "# DD\n",
    "# 去掉 20数据不全 24没数据 25无法ICA\n",
    "sub_ids = [\n",
    "\n",
    "    \"pre4008_y\",\"pre4009_y\",\"pre4010_y\",\"pre4011_y\",\"pre4012_y\",\"pre4013_y\",\n",
    "    \"pre4014_y\",\"pre4015_y\",\"pre4016_y\",\"pre4017_y\", \"pre4018_y\",\"pre4019_y\",\n",
    "    \"pre4021_y\",\"pre4022_y\",\"pre4023_y\",\"pre4026_y\",\n",
    "    \"pre4027_y\",\"pre4028_y\",\"pre4029_y\",\"pre4030_y\",\"pre4031_y\",\"pre4032_y\",\n",
    "    \"pre4033_y\",\"pre4034_y\",\n",
    "\n",
    "]\n",
    "sub_ids = [\n",
    "\n",
    "    \"pre4008_y\",\"pre4009_y\",\"pre4010_y\",\"pre4011_y\",\"pre4012_y\",\"pre4013_y\",\n",
    "    \"pre4014_y\",\"pre4015_y\",\"pre4016_y\",\"pre4017_y\", \"pre4018_y\",\"pre4019_y\",\n",
    "    \"pre4021_y\",\"pre4022_y\",\"pre4023_y\",\"pre4026_y\",\n",
    "    \"pre4027_y\",\"pre4028_y\",\"pre4029_y\",\"pre4030_y\"\n",
    "]\n",
    "# DD组\n",
    "sub_ids = [\n",
    "            'pre4010_y','pre4012_y','pre4013_y','pre4015_y','pre4017_y','pre4018_y','pre4019_y','pre4021_y','pre4022_y','pre4023_y','pre4026_y','pre4027_y','pre4030_y',\n",
    "          ]\n",
    "# 非DD组\n",
    "# sub_ids = [\n",
    "#            'pre4008_y','pre4009_y','pre4011_y','pre4014_y','pre4028_y','pre4029_y'\n",
    "#          ]\n",
    "\n",
    "\n",
    "# # 正常儿童\n",
    "# sub_ids = [\n",
    "#\n",
    "#      \"pre4003_y\",\"pre4007_y\",\"pre4008_y\",\"pre4009_y\",\"pre4010_y\",\"pre4011_y\",\"pre4012_y\",\"pre4013_y\"\n",
    "#\n",
    "# ]\n",
    "\n",
    "file_path = 'E:\\实验\\阅读困难\\数据处理\\pre4\\data\\\\6epoch_clean_RSA\\\\'\n",
    "channels_nieye = ['M1','T7','P7','TP7','M2','T8','P8','TP8','CP5','CP6','C5','C6']\n",
    "channels_nieye = ['T7','P7','TP7','M2','T8','P8','TP8','CP5','CP6','C5','C6']\n",
    "# 左右脑 偏侧化.\n",
    "channels_left = ['Fp1',  'AF3',  'F7', 'F5', 'F3', 'F1',  'FT7', 'FC5', 'FC3', 'FC1',  'T7', 'C5', 'C3', 'C1',   'TP7', 'CP5', 'CP3', 'CP1',  'P7', 'P5', 'P3', 'P1',   'PO7', 'PO5', 'PO3',  'O1', ]\n",
    "\n",
    "channels_right = ['Fp2','AF4',  'F2', 'F4', 'F6', 'F8', 'FC2', 'FC4', 'FC6', 'FT8','C2', 'C4', 'C6', 'T8', 'CP2', 'CP4', 'CP6', 'TP8', 'M2', 'P2', 'P4', 'P6', 'P8','PO4', 'PO6', 'PO8','O2',]\n",
    "\n",
    "channels_all = ['Fp1', 'Fpz', 'Fp2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'M2', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POz', 'PO4', 'PO6', 'PO8', 'O1', 'Oz', 'O2', ]\n",
    "\n",
    "\n",
    "channels_all = channels_right\n",
    "num_channel = len(channels_all)\n",
    "\n",
    "for sub_id in sub_ids:\n",
    "    data_path = file_path + sub_id + '_RSA-epo.fif'\n",
    "\n",
    "    epochs_all = mne.read_epochs(fname=data_path)\n",
    "    # 如果只想看某一部分的脑区,配合更改ndarray的维度\n",
    "    epochs_all = epochs_all.pick(picks=channels_all)\n",
    "\n",
    "    list_epochs_all.append(epochs_all)\n",
    "\n",
    "'''\n",
    "思路，先求ERP，然后再给ndarray，然后再计算RDM\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:28:17.355142Z",
     "start_time": "2023-05-27T16:27:23.255569600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "生成每种条件对应的evoked\n",
    "而且是按照次序\n",
    "'''\n",
    "num_channel = len(channels_all)\n",
    "conds = ['101', '102', '103', '104', '111', '112', '113', '114', '121', '122', '123', '124', '131', '132', '133', '134', ]\n",
    "\n",
    "eegdata = np.zeros([len(sub_ids),16, num_channel, 1001], dtype=np.float32)\n",
    "#初始值\n",
    "subindex = 0\n",
    "for m in range(len(sub_ids)):\n",
    "    #单个被试的数据\n",
    "    subdata = np.zeros([16, num_channel, 1001], dtype=np.float32)\n",
    "    for i in range(len(conds)):\n",
    "        epochs = list_epochs_all[m][conds[i]]\n",
    "        evoked = epochs.average()\n",
    "        data = evoked.data\n",
    "        subdata[i] = data\n",
    "    eegdata[m] = subdata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:28:26.419158200Z",
     "start_time": "2023-05-27T16:28:17.550206400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# shape of megdata: [n_subs, n_cons, n_chls, n_ts] -> [n_cons, n_subs, n_chls, n_ts]\n",
    "eegdata = np.transpose(eegdata, (1, 0, 2, 3))\n",
    "\n",
    "# shape of megdata: [n_cons, n_subs, n_chls, n_ts] -> [n_cons, n_subs, n_trials, n_chls, n_ts]\n",
    "# here data is averaged, so set n_trials = 1\n",
    "eegdata = np.reshape(eegdata, [16, len(sub_ids), 1, num_channel, 1001])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:28:26.435113200Z",
     "start_time": "2023-05-27T16:28:26.425140200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing RDMs\n",
      "\n",
      "RDMs computing finished!\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the RDM based on the data during 190ms-210ms\n",
    "#sub_opt=1 indicate不止一个被试。\n",
    "#The shape of EEGdata must be [n_cons, n_subs, n_trials, n_chls, n_ts].\n",
    "# Sometimes, the numbers of trials under different conditions are not same. In NeuroRA, we recommend users to average\n",
    "#     the trials under a same condition firstly in this situation. Thus, the shape of input (EEG_data) should be\n",
    "#     [n_cons, n_subs, 1, n_chls, n_ts].\n",
    "\n",
    "\n",
    "rdm = eegRDM(eegdata[:, :, :, :, 340:350])\n",
    "# Plot this RDM\n",
    "plot_rdm(rdm[0], percentile=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:28:28.278909700Z",
     "start_time": "2023-05-27T16:28:26.664135600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate the RDMs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing RDMs\n",
      "Calculating: [====================================================================================================] 100.00%\n",
      "RDMs computing finished!\n"
     ]
    }
   ],
   "source": [
    "# Calculate the RDMs by a 10ms time-window\n",
    "# (raw sampling requency is 1000Hz, so here time_win=10ms/(1s/1000Hz)/1000=10)\n",
    "# sub_opt = 1\n",
    "\n",
    "# 默认窗口是50，那么就是 （1000-50）/5 = 190\n",
    "#\n",
    "\n",
    "rdms = eegRDM(eegdata, time_opt=1, time_win=50, time_step=5, sub_opt=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:41:50.908914400Z",
     "start_time": "2023-05-27T16:28:28.284893700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Plot the RDM of -100ms, 0ms, 50ms, 100ms, 150ms, 200ms\n",
    "times = [0, 10, ]\n",
    "for t in times:\n",
    "    plot_rdm(rdms[1,t], percentile=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:41:51.172211300Z",
     "start_time": "2023-05-27T16:41:51.079458200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 辅音_理论模型\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "辅音_理论模型\n",
    "'''\n",
    "\n",
    "RDM_model_fuyin = np.zeros([16,16], dtype=np.float32)\n",
    "# for i in range(20):\n",
    "#     for j in range(20):\n",
    "#         if abs(i-j)<=3:\n",
    "#             RDM_model_fuyin[i,j] = 0\n",
    "#         else:\n",
    "#             RDM_model_fuyin[i,j] =\n",
    "zeroM = np.zeros([4,4], dtype=np.float32)\n",
    "oneM =  np.ones((4, 4), dtype=np.float32)\n",
    "\n",
    "a1=np.concatenate((zeroM,oneM,oneM,oneM),axis = 1)\n",
    "a2=np.concatenate((oneM,zeroM,oneM,oneM),axis = 1)\n",
    "a3=np.concatenate((oneM,oneM,zeroM,oneM),axis = 1)\n",
    "a4=np.concatenate((oneM,oneM,oneM,zeroM),axis = 1)\n",
    "\n",
    "RDM_model_fuyin = np.concatenate((a1,a2,a3,a4),axis=0)\n",
    "plot_rdm(RDM_model_fuyin, percentile=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:42:00.494612200Z",
     "start_time": "2023-05-27T16:42:00.356489Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing similarities\n",
      "\n",
      "Computing finished!\n",
      "\n",
      "Permutation test\n",
      "Calculating: [====================================================================================================] 100.00%\n",
      "Cluster-based permutation test finished!\n",
      "\n",
      "\n",
      "Significant time-windows:\n",
      "305ms to 400ms\n",
      "540ms to 625ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# （sub,times,2）\n",
    "corrs_EEGvsFuyin = rdms_corr(RDM_model_fuyin, rdms)\n",
    "%matplotlib qt\n",
    "# Plot the corrs1\n",
    "# corrs1 = np.reshape(corrs1, [1, 191, 2])\n",
    "# plot_corrs_by_time(corrs1, time_unit=[-0.2, 0.005])\n",
    "from neurora.rsa_plot import plot_tbytsim_withstats\n",
    "from neurora.stuff import clusterbased_permutation_1d_1samp_1sided\n",
    "\n",
    "#配合RDMS的时间窗是 50ms，步长是5ms = 0.005\n",
    "# start_time =\n",
    "ps_EEGvsFuyin =  plot_tbytsim_withstats(corrs_EEGvsFuyin, start_time=-0.15, end_time=0.805, time_interval=0.005, p=0.05,clusterp=0.05,stats_time=[0,0.8],color='b', xlim=(-0.2,1), fontsize=9)\n",
    "\n",
    "# plot_tbytsim_withstats 内嵌了  clusterbased_permutation_1d_1samp_1sided,统计部分由这个函数来完成的.\n",
    "# similarities = corrs_EEGvsFuyin[:, :, 0]\n",
    "# clusterbased_permutation_1d_1samp_1sided(similarities)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:42:31.249167700Z",
     "start_time": "2023-05-27T16:42:04.893454700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 保存结果"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "'''\n",
    "保存corrs_EEGvsFuyin\n",
    "\n",
    "1 需要算出极大值和对应的时间点-算峰值的方法 ---为了和行为做相关.\n",
    "\n",
    "2 算显著时间点均值\n",
    "\n",
    "'''\n",
    "\n",
    "# 问题:这里应该保存 -200 - 800ms的 还是保存 显著的时间窗口内的呢?\n",
    "# 应该保存窗口内的,不然没有做的意义了.\n",
    "# idea 可以用 ps来进行窗口的限制 截取对应的时间窗\n",
    "np.save('./脑电结果/corrs_EEGvsFuyin_DD_颞叶.npy', corrs_EEGvsFuyin)\n",
    "np.save('./脑电结果/ps_EEGvsFuyin_DD_颞叶.npy', ps_EEGvsFuyin)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T11:21:35.109814800Z",
     "start_time": "2023-05-24T11:21:34.964894800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 音调_理论模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "音调 模型\n",
    "'''\n",
    "\n",
    "RDM_model_yindiao = np.zeros([16,16], dtype=np.float32)\n",
    "\n",
    "\n",
    "oneM =  np.ones((4, 4), dtype=np.float32)\n",
    "for i in range(4):\n",
    "    oneM[i][i] = 0\n",
    "zeroM = oneM\n",
    "\n",
    "a1=np.concatenate((zeroM,oneM,oneM,oneM,),axis = 1)\n",
    "a2=np.concatenate((oneM,zeroM,oneM,oneM,),axis = 1)\n",
    "a3=np.concatenate((oneM,oneM,zeroM,oneM,),axis = 1)\n",
    "a4=np.concatenate((oneM,oneM,oneM,zeroM,),axis = 1)\n",
    "\n",
    "RDM_model_yindiao = np.concatenate((a1,a2,a3,a4),axis=0)\n",
    "\n",
    "plot_rdm(RDM_model_yindiao, percentile=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:42:52.609365200Z",
     "start_time": "2023-05-27T16:42:52.470736100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing similarities\n",
      "\n",
      "Computing finished!\n",
      "\n",
      "Significant time-windows:\n"
     ]
    }
   ],
   "source": [
    "# Calculate the representational similarity between 200ms and all the time points\n",
    "corrs_EEGvsYindiao = rdms_corr(RDM_model_yindiao, rdms)\n",
    "\n",
    "from neurora.rsa_plot import plot_tbytsim_withstats\n",
    "\n",
    "#配合RDMS的时间窗是 50ms，步长是5ms = 0.005\n",
    "ps_EEGvsYindiao = plot_tbytsim_withstats(corrs_EEGvsYindiao, start_time=-0.15, end_time=0.805, time_interval=0.005, p=0.05,clusterp=0.05,stats_time=[0,0.8], xlim=(-0.2,1), fontsize=9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:42:57.757512300Z",
     "start_time": "2023-05-27T16:42:55.496172300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "np.save('./脑电结果/corrs_EEGvsYindiao_DD_颞叶.npy', corrs_EEGvsYindiao)\n",
    "np.save('./脑电结果/ps_EEGvsYindiao_DD_颞叶.npy', ps_EEGvsYindiao)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T11:25:48.960303Z",
     "start_time": "2023-05-24T11:25:48.849598700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fo模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "更精细的构造方法 slope和height\n",
    "\n",
    "'''\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('E:\\实验\\阅读困难\\数据处理\\pre2beishi_RSA_ASSR46\\RSA\\刺激space\\\\f0的slope和height.xlsx')\n",
    "\n",
    "RDM_model_double = np.zeros([20,20], dtype=np.float32)\n",
    "for i in range(len(df)):\n",
    "\n",
    "    height1 = df['height'][i]\n",
    "    slope1 = df['slope'][i]\n",
    "\n",
    "    for j in range(len(df)):\n",
    "\n",
    "        height2= df['height'][j]\n",
    "        slope2 = df['slope'][j]\n",
    "\n",
    "        '''\n",
    "        计算公式\n",
    "        '''\n",
    "        distance = math.sqrt(math.pow((height2-height1),2)+math.pow((slope2-slope1),2))\n",
    "        # print(distance)\n",
    "\n",
    "        '''\n",
    "        填写到合适的矩阵位置上。\n",
    "        '''\n",
    "        RDM_model_double[i][j] = distance\n",
    "plot_rdm(RDM_model_double, percentile=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "corrs_f0 = rdms_corr(RDM_model_double, rdms)\n",
    "\n",
    "#配合RDMS的时间窗是 50ms，步长是5ms = 0.005\n",
    "plot_tbytsim_withstats(corrs_f0, start_time=-0.15, end_time=0.805, time_interval=0.005, p=0.1,clusterp=0.1,stats_time=[0,0.8])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 行为模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "基于行为数据的model RDM\n",
    "'''\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# 指定要读取的 .mat 文件路径\n",
    "file_path_tone = \"E:\\实验\\阅读困难\\数据处理\\pre4\\RSA\\models矩阵\\\\toneRDM.mat\"  # 将 \"path/to/your/file.mat\" 替换为实际的文件路径\n",
    "# 使用 loadmat 函数读取 .mat 文件\n",
    "RDM_model_yindiao_xw = loadmat(file_path_tone)['final_rdm']\n",
    "\n",
    "# 指定要读取的 .mat 文件路径\n",
    "file_path_consonat = \"E:\\实验\\阅读困难\\数据处理\\pre4\\RSA\\models矩阵\\\\consonantRDM.mat\"  # 将 \"path/to/your/file.mat\" 替换为实际的文件路径\n",
    "# 使用 loadmat 函数读取 .mat 文件\n",
    "RDM_model_fuyin_xw = loadmat(file_path_consonat)['new_rdm']\n",
    "\n",
    "# plot_rdm(RDM_model_yindiao_xw, percentile=True)\n",
    "plot_rdm(RDM_model_fuyin_xw, percentile=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:43:03.152956300Z",
     "start_time": "2023-05-27T16:43:02.986401500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing similarities\n",
      "\n",
      "Computing finished!\n",
      "\n",
      "Permutation test\n",
      "Calculating: [====================================================================================================] 100.00%\n",
      "Cluster-based permutation test finished!\n",
      "\n",
      "\n",
      "Significant time-windows:\n",
      "290ms to 420ms\n",
      "515ms to 680ms\n",
      "705ms to 800ms\n"
     ]
    }
   ],
   "source": [
    "# Calculate the representational similarity between 200ms and all the time points\n",
    "corrs_EEGvsFuyin_behavior = rdms_corr(RDM_model_fuyin_xw, rdms)\n",
    "#配合RDMS的时间窗是 50ms，步长是5ms = 0.005\n",
    "ps_corrs_EEGvsFuyin_behavior = plot_tbytsim_withstats(corrs_EEGvsFuyin_behavior, start_time=-0.15, end_time=0.805, time_interval=0.005, p=0.05,clusterp=0.05,stats_time=[0,0.8], xlim=[-0.2,1], fontsize=9, color='b')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:43:57.244960200Z",
     "start_time": "2023-05-27T16:43:07.191069800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing similarities\n",
      "\n",
      "Computing finished!\n",
      "\n",
      "Significant time-windows:\n"
     ]
    }
   ],
   "source": [
    "from neurora.rsa_plot import plot_tbytsim_withstats\n",
    "corrs_EEGvsYindiao_behavior = rdms_corr(RDM_model_yindiao_xw, rdms)\n",
    "#配合RDMS的时间窗是 50ms，步长是5ms = 0.005\n",
    "ps_corrs_EEGvsYindiao_behavior = plot_tbytsim_withstats(corrs_EEGvsYindiao_behavior, start_time=-0.15, end_time=0.805, time_interval=0.005, p=0.05,clusterp=0.05, color='r',stats_time=[0,0.8], xlim=[-0.2,1], fontsize=9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T16:44:02.090892900Z",
     "start_time": "2023-05-27T16:43:59.973134300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save('./脑电结果/corrs_EEGvsFuyin_behavior_DD.npy', corrs_EEGvsFuyin_behavior)\n",
    "np.save('./脑电结果/ps_corrs_EEGvsFuyin_behavior_DD.npy', ps_corrs_EEGvsFuyin_behavior)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# RSA和行为数据做相关\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau, ttest_1samp, ttest_rel\n",
    "from skimage.measure import label\n",
    "import sys\n",
    "from neurora.stuff import get_cluster_index_1d_1sided\n",
    "from neurora.stuff import show_progressbar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import signal\n",
    "from scipy.stats import ttest_1samp\n",
    "from nilearn import plotting, datasets, surface\n",
    "import nibabel as nib\n",
    "from neurora.stuff import get_affine, correct_by_threshold, get_bg_ch2, get_bg_ch2bet, \\\n",
    "    clusterbased_permutation_1d_1samp_1sided, clusterbased_permutation_2d_1samp_1sided\n",
    "from decimal import Decimal\n",
    "\n",
    "behavior_data = [1588.5,1605.46,1460.06,1844.59,543.99,53.11,2389.72,437.71, 1051.18, 2320.96,2132.45,2124.64,  652.25, 2491.82, 1663.75, 1663.75, 418.07]\n",
    "def clusterbased_permutation_1d_1samp_1sided2(results, behavior_data=behavior_data, p_threshold=0.05, iter=5000, level=0):\n",
    "    \"\"\"\n",
    "    1-sample & 1-sided cluster based permutation test for 2-D results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    similarities : array\n",
    "        A similarity matrix.\n",
    "        The shape of similarities should be [n_subs, x, 0]. n_subs represents the number of subjects.\n",
    "    behavior_data : array\n",
    "        The behavior data for correlation calculation.\n",
    "    p_threshold : float. Default is 0.05.\n",
    "        The threshold of p-values.\n",
    "    iter : int. Default is 5000.\n",
    "        The times for iteration.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ps : float\n",
    "        The permutation test results, p-values.\n",
    "        The shape of ps is [x]. The values in ps should be 0 or 1, which represent not significant point or significant\n",
    "        point after cluster-based permutation test, respectively.\n",
    "    \"\"\"\n",
    "    nsubs, x, _ = np.shape(similarities)\n",
    "\n",
    "    ps = np.zeros([x])\n",
    "    ts = np.zeros([x])\n",
    "    for t in range(x):\n",
    "        time_point_data = similarities[:, t, 0]\n",
    "        ts[t], p = pearsonr(behavior_data, time_point_data)\n",
    "        if p < p_threshold and ts[t] > 0:\n",
    "            ps[t] = 1\n",
    "        else:\n",
    "            ps[t] = 0\n",
    "\n",
    "    cluster_index, cluster_n = get_cluster_index_1d_1sided(ps)\n",
    "    print(cluster_n)\n",
    "\n",
    "    if cluster_n != 0:\n",
    "        cluster_ts = np.zeros([cluster_n])\n",
    "        for i in range(cluster_n):\n",
    "            for t in range(x):\n",
    "                if cluster_index[t] == i + 1:\n",
    "                    cluster_ts[i] = cluster_ts[i] + ts[t]\n",
    "\n",
    "        permu_ts = np.zeros([iter])\n",
    "        chance = np.full([nsubs], level)\n",
    "        print(\"\\nPermutation test\")\n",
    "\n",
    "        for i in range(iter):\n",
    "            permu_cluster_ts = np.zeros([cluster_n])\n",
    "            for j in range(cluster_n):\n",
    "                for t in range(x):\n",
    "                    if cluster_index[t] == j + 1:\n",
    "                        v = np.hstack((results[:, t], chance))\n",
    "                        vshuffle = np.random.permutation(v)\n",
    "                        v1 = vshuffle[:nsubs]\n",
    "                        v2 = vshuffle[nsubs:]\n",
    "                        permu_cluster_ts[j] = permu_cluster_ts[j] + ttest_rel(v1, v2, alternative=\"greater\")[0]\n",
    "            permu_ts[i] = np.max(permu_cluster_ts)\n",
    "            show_progressbar(\"Calculating\", (i+1)*100/iter)\n",
    "            if i == (iter - 1):\n",
    "                print(\"\\nCluster-based permutation test finished!\\n\")\n",
    "\n",
    "        for i in range(cluster_n):\n",
    "            index = 0\n",
    "            for j in range(iter):\n",
    "                if cluster_ts[i] > permu_ts[j]:\n",
    "                    index = index + 1\n",
    "            if index < iter * (1-p_threshold):\n",
    "                for t in range(x):\n",
    "                    if cluster_index[t] == i + 1:\n",
    "                        ps[t] = 0\n",
    "\n",
    "    return ps\n",
    "\n",
    "def plot_tbytsim_withstats(similarities, start_time=0, end_time=1, smooth=True, p=0.05, cbpt=True, color='r',\n",
    "                           lim=[-0.1, 0.8], figsize=[6.4, 3.6], x0=0, fontsize=16):\n",
    "\n",
    "    \"\"\"\n",
    "    Plot the time-by-time Similarities with statistical results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    similarities : array\n",
    "        The Similarities.\n",
    "        The size of similarities should be [n_subs, n_ts] or [n_subs, n_ts, 2]. n_subs, n_ts represent the number of\n",
    "        subjects and number of time-points. 2 represents the similarity and a p-value.\n",
    "    start_time : int or float. Default is 0.\n",
    "        The start time.\n",
    "    end_time : int or float. Default is 1.\n",
    "        The end time.\n",
    "    smooth : bool True or False. Default is True.\n",
    "        Smooth the results or not.\n",
    "    p : float. Default is 0.05.\n",
    "        The threshold of p-values.\n",
    "    cbpt : bool True or False. Default is True.\n",
    "        Conduct cluster-based permutation test or not.\n",
    "    color : matplotlib color or None. Default is 'r'.\n",
    "        The color for the curve.\n",
    "    lim : array or list [min, max]. Default is [-0.1, 0.8].\n",
    "        The corrs view lims.\n",
    "    figsize : array or list, [size_X, size_Y]. Default is [6.4, 3.6].\n",
    "        The size of the figure.\n",
    "    x0 : float. Default is 0.\n",
    "        The Y-axis is at x=x0.\n",
    "    fontsize : int or float. Default is 16.\n",
    "        The fontsize of the labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(np.shape(similarities)) < 2 or len(np.shape(similarities)) > 3:\n",
    "\n",
    "        return \"Invalid input!\"\n",
    "\n",
    "    n = len(np.shape(similarities))\n",
    "\n",
    "    minlim = lim[0]\n",
    "    maxlim = lim[1]\n",
    "\n",
    "    if n == 3:\n",
    "        similarities = similarities[:, :, 0]\n",
    "\n",
    "    nsubs = np.shape(similarities)[0]\n",
    "    nts = np.shape(similarities)[1]\n",
    "\n",
    "    tstep = float((end_time-start_time)/nts)\n",
    "\n",
    "    if smooth is True:\n",
    "        for sub in range(nsubs):\n",
    "            for t in range(nts):\n",
    "\n",
    "                if t<=1:\n",
    "                    similarities[sub, t] = np.average(similarities[sub, :t+3])\n",
    "                if t>1 and t<(nts-2):\n",
    "                    similarities[sub, t] = np.average(similarities[sub, t-2:t+3])\n",
    "                if t>=(nts-2):\n",
    "                    similarities[sub, t] = np.average(similarities[sub, t-2:])\n",
    "\n",
    "    avg = np.average(similarities, axis=0)\n",
    "    err = np.zeros([nts], dtype=np.float)\n",
    "\n",
    "    for t in range(nts):\n",
    "        err[t] = np.std(similarities[:, t], ddof=1)/np.sqrt(nsubs)\n",
    "\n",
    "    if cbpt == True:\n",
    "        ps = clusterbased_permutation_1d_1samp_1sided2(similarities, level=0, p_threshold=p)\n",
    "    else:\n",
    "        ps = np.zeros([nts])\n",
    "        for t in range(nts):\n",
    "            ps[t] = ttest_1samp(similarities[:, t], 0, alternative=\"greater\")[1]\n",
    "            if ps[t] < p:\n",
    "                ps[t] = 1\n",
    "            else:\n",
    "                ps[t] = 0\n",
    "\n",
    "    for t in range(nts):\n",
    "        if ps[t] == 1:\n",
    "            plt.plot(t*tstep+start_time, (maxlim-minlim)*0.9+minlim, 's', color=color, alpha=1)\n",
    "            xi = [t*tstep+start_time, t*tstep+tstep+start_time]\n",
    "            ymin = [0]\n",
    "            ymax = [avg[t]-err[t]]\n",
    "            plt.fill_between(xi, ymax, ymin, facecolor=color, alpha=0.1)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(figsize[0], figsize[1])\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_linewidth(3)\n",
    "    ax.spines[\"left\"].set_position((\"data\", x0))\n",
    "    ax.spines[\"bottom\"].set_linewidth(3)\n",
    "    ax.spines['bottom'].set_position(('data', 0))\n",
    "\n",
    "    x = np.arange(start_time+0.5*tstep, end_time+0.5*tstep, tstep)\n",
    "    plt.fill_between(x, avg + err, avg - err, facecolor=color, alpha=0.8)\n",
    "    plt.ylim(minlim, maxlim)\n",
    "    plt.xlim(start_time, end_time)\n",
    "    plt.tick_params(labelsize=12)\n",
    "    plt.xlabel(\"Time (s)\", fontsize=fontsize)\n",
    "    plt.ylabel(\"Representational Similarity\", fontsize=fontsize)\n",
    "    plt.show()\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "ps_testBehave = clusterbased_permutation_1d_1samp_1sided2(results=corrs1[:, :, 0], behavior_data=behavior_data, p_threshold=0.05, iter=1000)\n",
    "\n",
    "plot_tbytsim_withstats(corrs2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "这是想在RSA的基础上再封装一次.\n",
    "用RSA每个时间点上的相关系数 和 行为数据做一次相关,\n",
    "相当于用行为数据扫一遍\n",
    "\n",
    "其实不应该扫,直接拿RSA显著的区域的值--峰值 来做一次相关就可以了.\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 行为数据（一维数组，17个值）\n",
    "behavior_data = [1588.5,1605.46,1460.06,1844.59,543.99,53.11,2389.72,437.71,-2438.1, 1051.18, -973.79, -2204.05,-2295.48,2320.96,2132.45,2124.64, -2228.45, -694.64, 652.25, 2491.82, 1663.75, 1663.75, 418.07]\n",
    "behavior_data = [1588.5,1605.46,1460.06,1844.59,543.99,53.11,2389.72,437.71, 1051.18, 2320.96,2132.45,2124.64,  652.25, 2491.82, 1663.75, 1663.75, 418.07]\n",
    "# similarities数据（17个被试*191个时间点*2）\n",
    "similarities = corrs_EEGvsFuyin_behavior\n",
    "\n",
    "# 创建一个空的191x2矩阵来存储相关系数和p值\n",
    "correlation_matrix = np.zeros((191, 2))\n",
    "\n",
    "# 遍历每个时间点\n",
    "for t in range(191):\n",
    "    # 提取当前时间点上的17个数据\n",
    "    time_point_data = similarities[:, t, 0]\n",
    "\n",
    "    # 计算行为数据和当前时间点数据的相关系数和p值\n",
    "    correlation_coefficient, p_value = pearsonr(behavior_data, time_point_data)\n",
    "\n",
    "    # 将相关系数和p值填入矩阵\n",
    "    correlation_matrix[t, 0] = correlation_coefficient\n",
    "    correlation_matrix[t, 1] = p_value\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import mne_rsa\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T11:24:51.160237400Z",
     "start_time": "2023-05-28T11:24:51.057209500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mne12",
   "language": "python",
   "display_name": "Python(mne12)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
