{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Spatiotemporal permutation F-test on full sensor data\n",
    "\n",
    "Tests for differential evoked responses in at least\n",
    "one condition using a permutation clustering test.\n",
    "The FieldTrip neighbor templates will be used to determine\n",
    "the adjacency between sensors. This serves as a spatial prior\n",
    "to the clustering. Spatiotemporal clusters will then\n",
    "be visualized using custom matplotlib code.\n",
    "\n",
    "Here, the unit of observation is epochs from a specific study subject.\n",
    "However, the same logic applies when the unit observation is\n",
    "a number of study subject each of whom contribute their own averaged\n",
    "data (i.e., an average of their epochs). This would then be considered\n",
    "an analysis at the \"2nd level\".\n",
    "\n",
    "See the [FieldTrip tutorial](ft_cluster_) for a caveat regarding\n",
    "the possible interpretation of \"significant\" clusters.\n",
    "\n",
    "For more information on cluster-based permutation testing in MNE-Python,\n",
    "see also: `tut-cluster-one-samp-tfr`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Authors: Denis Engemann <denis.engemann@gmail.com>\n",
    "#          Jona Sassenhagen <jona.sassenhagen@gmail.com>\n",
    "#          Alex Rockhill <aprockhill@mailbox.org>\n",
    "#          Stefan Appelhoff <stefan.appelhoff@mailbox.org>\n",
    "#\n",
    "# License: BSD-3-Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import scipy.stats\n",
    "\n",
    "import mne\n",
    "from mne.stats import spatio_temporal_cluster_test, combine_adjacency\n",
    "from mne.datasets import sample\n",
    "from mne.channels import find_ch_adjacency\n",
    "from mne.viz import plot_compare_evokeds\n",
    "from mne.time_frequency import tfr_morlet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file E:\\Python LYW\\RSA\\MNEtutorial\\DATA\\MNE-sample-data\\MEG\\sample\\sample_audvis_filt-0-40_raw.fif...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n",
      "    Range : 6450 ... 48149 =     42.956 ...   320.665 secs\n",
      "Ready.\n",
      "Reading 0 ... 41699  =      0.000 ...   277.709 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 497 samples (3.310 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = sample.data_path()\n",
    "meg_path = data_path / 'MEG' / 'sample'\n",
    "raw_fname = meg_path / 'sample_audvis_filt-0-40_raw.fif'\n",
    "event_fname = meg_path / 'sample_audvis_filt-0-40_raw-eve.fif'\n",
    "event_id = {'Aud/L': 1, 'Aud/R': 2, 'Vis/L': 3, 'Vis/R': 4}\n",
    "tmin = -0.2\n",
    "tmax = 0.5\n",
    "\n",
    "# Setup for reading the raw data\n",
    "raw = mne.io.read_raw_fif(raw_fname, preload=True)\n",
    "raw.filter(1, 30)\n",
    "events = mne.read_events(event_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read epochs for the channel of interest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 3)\n",
      "4 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 106 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1711']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1711']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "49 bad epochs dropped\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>\n",
      "Dropped 19 epochs: 50, 51, 84, 93, 95, 96, 129, 146, 149, 150, 154, 156, 157, 189, 194, 200, 202, 210, 211\n"
     ]
    }
   ],
   "source": [
    "picks = mne.pick_types(raw.info, meg='mag', eog=True)\n",
    "\n",
    "reject = dict(mag=4e-12, eog=150e-6)\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, picks=picks,\n",
    "                    baseline=None, reject=reject, preload=True)\n",
    "\n",
    "epochs.drop_channels(['EOG 061'])\n",
    "epochs.equalize_event_counts(event_id)\n",
    "\n",
    "# Obtain the data as a 3D matrix and transpose it such that\n",
    "# the dimensions are as expected for the cluster permutation test:\n",
    "# n_epochs × n_times × n_channels\n",
    "X = [epochs[event_name].get_data() for event_name in event_id]\n",
    "X = [np.transpose(x, (0, 2, 1)) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Find the FieldTrip neighbor definition to setup sensor adjacency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading adjacency matrix for neuromag306mag.\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'mne.viz' has no attribute 'plot_ch_adjacency'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m adjacency, ch_names \u001B[38;5;241m=\u001B[39m find_ch_adjacency(epochs\u001B[38;5;241m.\u001B[39minfo, ch_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmag\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(adjacency))  \u001B[38;5;66;03m# it's a sparse matrix!\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mmne\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mviz\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot_ch_adjacency\u001B[49m(epochs\u001B[38;5;241m.\u001B[39minfo, adjacency, ch_names)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'mne.viz' has no attribute 'plot_ch_adjacency'"
     ]
    }
   ],
   "source": [
    "adjacency, ch_names = find_ch_adjacency(epochs.info, ch_type='mag')\n",
    "\n",
    "print(type(adjacency))  # it's a sparse matrix!\n",
    "\n",
    "mne.viz.plot_ch_adjacency(epochs.info, adjacency, ch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compute permutation statistic\n",
    "\n",
    "How does it work? We use clustering to \"bind\" together features which are\n",
    "similar. Our features are the magnetic fields measured over our sensor\n",
    "array at different times. This reduces the multiple comparison problem.\n",
    "To compute the actual test-statistic, we first sum all F-values in all\n",
    "clusters. We end up with one statistic for each cluster.\n",
    "Then we generate a distribution from the data by shuffling our conditions\n",
    "between our samples and recomputing our clusters and the test statistics.\n",
    "We test for the significance of a given cluster by computing the probability\n",
    "of observing a cluster of that size\n",
    ":footcite:`MarisOostenveld2007,Sassenhagen2019`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We are running an F test, so we look at the upper tail\n",
    "# see also: https://stats.stackexchange.com/a/73993\n",
    "tail = 1\n",
    "\n",
    "# We want to set a critical test statistic (here: F), to determine when\n",
    "# clusters are being formed. Using Scipy's percent point function of the F\n",
    "# distribution, we can conveniently select a threshold that corresponds to\n",
    "# some alpha level that we arbitrarily pick.\n",
    "alpha_cluster_forming = 0.001\n",
    "\n",
    "# For an F test we need the degrees of freedom for the numerator\n",
    "# (number of conditions - 1) and the denominator (number of observations\n",
    "# - number of conditions):\n",
    "n_conditions = len(event_id)\n",
    "n_observations = len(X[0])\n",
    "dfn = n_conditions - 1\n",
    "dfd = n_observations - n_conditions\n",
    "\n",
    "# Note: we calculate 1 - alpha_cluster_forming to get the critical value\n",
    "# on the right tail\n",
    "f_thresh = scipy.stats.f.ppf(1 - alpha_cluster_forming, dfn=dfn, dfd=dfd)\n",
    "\n",
    "# run the cluster based permutation analysis\n",
    "cluster_stats = spatio_temporal_cluster_test(X, n_permutations=1000,\n",
    "                                             threshold=f_thresh, tail=tail,\n",
    "                                             n_jobs=None, buffer_size=None,\n",
    "                                             adjacency=adjacency)\n",
    "F_obs, clusters, p_values, _ = cluster_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Note how we only specified an adjacency for sensors! However,\n",
    "          because we used :func:`mne.stats.spatio_temporal_cluster_test`,\n",
    "          an adjacency for time points was automatically taken into\n",
    "          account. That is, at time point N, the time points N - 1 and\n",
    "          N + 1 were considered as adjacent (this is also called \"lattice\n",
    "          adjacency\"). This is only possible because we ran the analysis on\n",
    "          2D data (times × channels) per observation ... for 3D data per\n",
    "          observation (e.g., times × frequencies × channels), we will need\n",
    "          to use :func:`mne.stats.combine_adjacency`, as shown further\n",
    "          below.</p></div>\n",
    "\n",
    "Note also that the same functions work with source estimates.\n",
    "The only differences are the origin of the data, the size,\n",
    "and the adjacency definition.\n",
    "It can be used for single trials or for groups of subjects.\n",
    "\n",
    "## Visualize clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We subselect clusters that we consider significant at an arbitrarily\n",
    "# picked alpha level: \"p_accept\".\n",
    "# NOTE: remember the caveats with respect to \"significant\" clusters that\n",
    "# we mentioned in the introduction of this tutorial!\n",
    "p_accept = 0.01\n",
    "good_cluster_inds = np.where(p_values < p_accept)[0]\n",
    "\n",
    "# configure variables for visualization\n",
    "colors = {\"Aud\": \"crimson\", \"Vis\": 'steelblue'}\n",
    "linestyles = {\"L\": '-', \"R\": '--'}\n",
    "\n",
    "# organize data for plotting\n",
    "evokeds = {cond: epochs[cond].average() for cond in event_id}\n",
    "\n",
    "# loop over clusters\n",
    "for i_clu, clu_idx in enumerate(good_cluster_inds):\n",
    "    # unpack cluster information, get unique indices\n",
    "    time_inds, space_inds = np.squeeze(clusters[clu_idx])\n",
    "    ch_inds = np.unique(space_inds)\n",
    "    time_inds = np.unique(time_inds)\n",
    "\n",
    "    # get topography for F stat\n",
    "    f_map = F_obs[time_inds, ...].mean(axis=0)\n",
    "\n",
    "    # get signals at the sensors contributing to the cluster\n",
    "    sig_times = epochs.times[time_inds]\n",
    "\n",
    "    # create spatial mask\n",
    "    mask = np.zeros((f_map.shape[0], 1), dtype=bool)\n",
    "    mask[ch_inds, :] = True\n",
    "\n",
    "    # initialize figure\n",
    "    fig, ax_topo = plt.subplots(1, 1, figsize=(10, 3))\n",
    "\n",
    "    # plot average test statistic and mark significant sensors\n",
    "    f_evoked = mne.EvokedArray(f_map[:, np.newaxis], epochs.info, tmin=0)\n",
    "    f_evoked.plot_topomap(times=0, mask=mask, axes=ax_topo, cmap='Reds',\n",
    "                          vmin=np.min, vmax=np.max, show=False,\n",
    "                          colorbar=False, mask_params=dict(markersize=10))\n",
    "    image = ax_topo.images[0]\n",
    "\n",
    "    # remove the title that would otherwise say \"0.000 s\"\n",
    "    ax_topo.set_title(\"\")\n",
    "\n",
    "    # create additional axes (for ERF and colorbar)\n",
    "    divider = make_axes_locatable(ax_topo)\n",
    "\n",
    "    # add axes for colorbar\n",
    "    ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    plt.colorbar(image, cax=ax_colorbar)\n",
    "    ax_topo.set_xlabel(\n",
    "        'Averaged F-map ({:0.3f} - {:0.3f} s)'.format(*sig_times[[0, -1]]))\n",
    "\n",
    "    # add new axis for time courses and plot time courses\n",
    "    ax_signals = divider.append_axes('right', size='300%', pad=1.2)\n",
    "    title = 'Cluster #{0}, {1} sensor'.format(i_clu + 1, len(ch_inds))\n",
    "    if len(ch_inds) > 1:\n",
    "        title += \"s (mean)\"\n",
    "    plot_compare_evokeds(evokeds, title=title, picks=ch_inds, axes=ax_signals,\n",
    "                         colors=colors, linestyles=linestyles, show=False,\n",
    "                         split_legend=True, truncate_yaxis='auto')\n",
    "\n",
    "    # plot temporal cluster extent\n",
    "    ymin, ymax = ax_signals.get_ylim()\n",
    "    ax_signals.fill_betweenx((ymin, ymax), sig_times[0], sig_times[-1],\n",
    "                             color='orange', alpha=0.3)\n",
    "\n",
    "    # clean up viz\n",
    "    mne.viz.tight_layout(fig=fig)\n",
    "    fig.subplots_adjust(bottom=.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Permutation statistic for time-frequencies\n",
    "\n",
    "Let's do the same thing with the time-frequency decomposition of the data\n",
    "(see `tut-sensors-time-freq` for a tutorial and\n",
    "`ex-tfr-comparison` for a comparison of time-frequency methods) to\n",
    "show how cluster permutations can be done on higher-dimensional data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "decim = 4\n",
    "freqs = np.arange(7, 30, 3)  # define frequencies of interest\n",
    "n_cycles = freqs / freqs[0]\n",
    "\n",
    "epochs_power = list()\n",
    "for condition in [epochs[k] for k in ('Aud/L', 'Vis/L')]:\n",
    "    this_tfr = tfr_morlet(condition, freqs, n_cycles=n_cycles,\n",
    "                          decim=decim, average=False, return_itc=False)\n",
    "    this_tfr.apply_baseline(mode='ratio', baseline=(None, 0))\n",
    "    epochs_power.append(this_tfr.data)\n",
    "\n",
    "# transpose again to (epochs, frequencies, times, channels)\n",
    "X = [np.transpose(x, (0, 2, 3, 1)) for x in epochs_power]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Remember the note on the adjacency matrix from above: For 3D data, as here,\n",
    "we must use :func:`mne.stats.combine_adjacency` to extend the\n",
    "sensor-based adjacency to incorporate the time-frequency plane as well.\n",
    "\n",
    "Here, the integer inputs are converted into a lattice and\n",
    "combined with the sensor adjacency matrix so that data at similar\n",
    "times and with similar frequencies and at close sensor locations are\n",
    "clustered together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# our data at each observation is of shape frequencies × times × channels\n",
    "tfr_adjacency = combine_adjacency(\n",
    "    len(freqs), len(this_tfr.times), adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can run the cluster permutation test, but first we have to set a\n",
    "threshold. This example decimates in time and uses few frequencies so we need\n",
    "to increase the threshold from the default value in order to have\n",
    "differentiated clusters (i.e., so that our algorithm doesn't just find one\n",
    "large cluster). For a more principled method of setting this parameter,\n",
    "threshold-free cluster enhancement may be used.\n",
    "See `disc-stats` for a discussion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This time we don't calculate a threshold based on the F distribution.\n",
    "# We might as well select an arbitrary threshold for cluster forming\n",
    "tfr_threshold = 15.0\n",
    "\n",
    "# run cluster based permutation analysis\n",
    "cluster_stats = spatio_temporal_cluster_test(\n",
    "    X, n_permutations=1000, threshold=tfr_threshold, tail=1, n_jobs=None,\n",
    "    buffer_size=None, adjacency=tfr_adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we can plot our results. It is difficult to visualize clusters in\n",
    "time-frequency-sensor space; plotting time-frequency spectrograms and\n",
    "plotting topomaps display time-frequency and sensor space respectively\n",
    "but they are difficult to combine. We will plot topomaps with the clustered\n",
    "sensors colored in white adjacent to spectrograms in order to provide a\n",
    "visualization of the results. This is a dimensionally limited view, however.\n",
    "Each sensor has its own significant time-frequencies, but, in order to\n",
    "display a single spectrogram, all the time-frequencies that are significant\n",
    "for any sensor in the cluster are plotted as significant. This is a\n",
    "difficulty inherent to visualizing high-dimensional data and should be taken\n",
    "into consideration when interpreting results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "F_obs, clusters, p_values, _ = cluster_stats\n",
    "good_cluster_inds = np.where(p_values < p_accept)[0]\n",
    "\n",
    "for i_clu, clu_idx in enumerate(good_cluster_inds):\n",
    "    # unpack cluster information, get unique indices\n",
    "    freq_inds, time_inds, space_inds = clusters[clu_idx]\n",
    "    ch_inds = np.unique(space_inds)\n",
    "    time_inds = np.unique(time_inds)\n",
    "    freq_inds = np.unique(freq_inds)\n",
    "\n",
    "    # get topography for F stat\n",
    "    f_map = F_obs[freq_inds].mean(axis=0)\n",
    "    f_map = f_map[time_inds].mean(axis=0)\n",
    "\n",
    "    # get signals at the sensors contributing to the cluster\n",
    "    sig_times = epochs.times[time_inds]\n",
    "\n",
    "    # initialize figure\n",
    "    fig, ax_topo = plt.subplots(1, 1, figsize=(10, 3))\n",
    "\n",
    "    # create spatial mask\n",
    "    mask = np.zeros((f_map.shape[0], 1), dtype=bool)\n",
    "    mask[ch_inds, :] = True\n",
    "\n",
    "    # plot average test statistic and mark significant sensors\n",
    "    f_evoked = mne.EvokedArray(f_map[:, np.newaxis], epochs.info, tmin=0)\n",
    "    f_evoked.plot_topomap(times=0, mask=mask, axes=ax_topo, cmap='Reds',\n",
    "                          vmin=np.min, vmax=np.max, show=False,\n",
    "                          colorbar=False, mask_params=dict(markersize=10))\n",
    "    image = ax_topo.images[0]\n",
    "\n",
    "    # create additional axes (for ERF and colorbar)\n",
    "    divider = make_axes_locatable(ax_topo)\n",
    "\n",
    "    # add axes for colorbar\n",
    "    ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    plt.colorbar(image, cax=ax_colorbar)\n",
    "    ax_topo.set_xlabel(\n",
    "        'Averaged F-map ({:0.3f} - {:0.3f} s)'.format(*sig_times[[0, -1]]))\n",
    "\n",
    "    # remove the title that would otherwise say \"0.000 s\"\n",
    "    ax_topo.set_title(\"\")\n",
    "\n",
    "    # add new axis for spectrogram\n",
    "    ax_spec = divider.append_axes('right', size='300%', pad=1.2)\n",
    "    title = 'Cluster #{0}, {1} spectrogram'.format(i_clu + 1, len(ch_inds))\n",
    "    if len(ch_inds) > 1:\n",
    "        title += \" (max over channels)\"\n",
    "    F_obs_plot = F_obs[..., ch_inds].max(axis=-1)\n",
    "    F_obs_plot_sig = np.zeros(F_obs_plot.shape) * np.nan\n",
    "    F_obs_plot_sig[tuple(np.meshgrid(freq_inds, time_inds))] = \\\n",
    "        F_obs_plot[tuple(np.meshgrid(freq_inds, time_inds))]\n",
    "\n",
    "    for f_image, cmap in zip([F_obs_plot, F_obs_plot_sig], ['gray', 'autumn']):\n",
    "        c = ax_spec.imshow(f_image, cmap=cmap, aspect='auto', origin='lower',\n",
    "                           extent=[epochs.times[0], epochs.times[-1],\n",
    "                                   freqs[0], freqs[-1]])\n",
    "    ax_spec.set_xlabel('Time (ms)')\n",
    "    ax_spec.set_ylabel('Frequency (Hz)')\n",
    "    ax_spec.set_title(title)\n",
    "\n",
    "    # add another colorbar\n",
    "    ax_colorbar2 = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    plt.colorbar(c, cax=ax_colorbar2)\n",
    "    ax_colorbar2.set_ylabel('F-stat')\n",
    "\n",
    "    # clean up viz\n",
    "    mne.viz.tight_layout(fig=fig)\n",
    "    fig.subplots_adjust(bottom=.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "- What is the smallest p-value you can obtain, given the finite number of\n",
    "  permutations? You can find the answers in the references\n",
    "  :footcite:`MarisOostenveld2007,Sassenhagen2019`.\n",
    "\n",
    "## References\n",
    ".. footbibliography::\n",
    "\n",
    ".. include:: ../../links.inc\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mne",
   "language": "python",
   "display_name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}